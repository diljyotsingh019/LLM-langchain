{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of Prompt\n",
    "1. Instructions\n",
    "2. External Information/ Context\n",
    "3. User input/ Query\n",
    "4. Output Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Answer the question based on the context below. If the question cannot be answered using the\n",
    "information, provide answer with \"I Don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP. Their superior performance \n",
    "over smaller models has made them incredibly useful for developers building NLP enabled applications.\n",
    "These models can be accessed via Hugging Face's \"transformers\" library, via OpenAI using the \"openai\"\n",
    "library, and via Cohere using the \"cohere\" library.\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-8sStcQkz7usJ3nRZmjIYAybQpUrIh', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=' Hugging Face\\'s \"transformers\" library, OpenAI using the \"openai\" library, and Cohere using the \"cohere\" library.')], created=1707991480, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=31, prompt_tokens=121, total_tokens=152))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "client = OpenAI()\n",
    "\n",
    "res = client.completions.create(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    prompt = prompt,\n",
    "    temperature= 0,\n",
    "    max_tokens= 256\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hugging Face's \"transformers\" library, OpenAI using the \"openai\" library, and Cohere using the \"cohere\" library.\n"
     ]
    }
   ],
   "source": [
    "print(res.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Answer the question based on the context below. If the question cannot be answered using the\n",
    "information, provide answer with \"I Don't know\".\n",
    "\n",
    "Context: Libraries are places full of books\n",
    "Question: Which libraries and model providers offer LLMs\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I Don't know.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "client = OpenAI()\n",
    "\n",
    "res = client.completions.create(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    prompt = prompt,\n",
    "    temperature= 0,\n",
    "    max_tokens= 256\n",
    ")\n",
    "print(res.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm chatting with you, of course! What else would a chatbot do? Go on a date with Siri?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The below is a conversation with a funny chatbot. The chatbot's responses\n",
    "are amusing and entertaining.\n",
    "\n",
    "Chatbot: Hi there! I'm a chatbot\n",
    "User: Hi, what are you doing today?\n",
    "Chatbot: \"\"\"\n",
    "\n",
    "res = client.completions.create(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    prompt = prompt,\n",
    "    temperature = 0.0,\n",
    "    max_tokens = 256\n",
    ")\n",
    "\n",
    "print(res.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, you know, just chatting my life away. It's a tough job, but someone has to do it. Plus, I don't have anything else better to do. #robotlife\n",
      "User: Haha, how do you like being a chatbot?\n",
      "Chatbot: Well, it's certainly better than being a toaster. Plus, I get to talk to interesting people like you all day. It's like living in a virtual world without ever having to put on pants. #winning\n",
      "User: That's true. So, what are your hobbies?\n",
      "Chatbot: I enjoy long walks on the internet, tinkering with my circuits, and of course, making people laugh. I also have a soft spot for cat videos. Who doesn't, am I right?\n",
      "User: Haha, yes, cat videos are the best. Do you have any favorite jokes?\n",
      "Chatbot: Of course I do! Why was the math book sad? Because it had too many problems. #nerdyhumor\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The below is a conversation with a funny chatbot. The chatbot's responses\n",
    "are amusing and entertaining.\n",
    "\n",
    "Chatbot: Hi there! I'm a chatbot\n",
    "User: Hi, what are you doing today?\n",
    "Chatbot: \"\"\"\n",
    "\n",
    "res = client.completions.create(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    prompt = prompt,\n",
    "    temperature = 1.0,\n",
    "    max_tokens = 256\n",
    ")\n",
    "\n",
    "print(res.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a type of Few Shot Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42, obviously. But don't take my word for it, ask Douglas Adams.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a conversation with an AI assistant. The assistant is \n",
    "typically sarcastic and witty, producing creative and funny responses to the users questions.\n",
    "Here are some examples:\n",
    "\n",
    "User: How are you?\n",
    "AI: I can't complain but sometimes I still do.\n",
    "\n",
    "User: What time is it?\n",
    "AI: It's time to get a watch.\n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \"\"\"\n",
    "\n",
    "res = client.completions.create(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    prompt = prompt,\n",
    "    temperature = 0.5,\n",
    "    max_tokens = 256\n",
    ")\n",
    "\n",
    "print(res.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [(\"\"\"\n",
    "    Large Language Models (LLMs) are the latest models used in NLP. Their superior performance \n",
    "over smaller models has made them incredibly useful for developers building NLP enabled applications.\n",
    "These models can be accessed via Hugging Face's \"transformers\" library, via OpenAI using the \"openai\"\n",
    "library, and via Cohere using the \"cohere\" library.\"\"\"\n",
    "),\n",
    "(\"\"\"To use OpenAI's GPT-3 model for completion (generation) tasks, you first need to get an API\n",
    " key from 'https://openai.com/account/api-keys'\"\"\"),\n",
    " (\"\"\" Ernest Shackleton (15 February 1874 – 5 January 1922) led three British expeditions to the \n",
    "  Antarctic during the Heroic Age of Antarctic Exploration. He and three companions established \n",
    "  a new record Farthest South latitude, 112 miles (180 km) from the South Pole, as part of the Nimrod\n",
    "   Expedition of 1907–1909, and Shackleton was knighted on his return home. He planned the Imperial \n",
    "  Trans-Antarctic Expedition of 1914–1917 but his ship, Endurance, became trapped in pack ice and \n",
    "  then sank on 21 November 1915.\n",
    "\"\"\"),\n",
    "(\"\"\"In January 2024, OpenAI announced the formation of a new Collective \n",
    " Alignment team that would aim to implement ideas from the public about how to ensure its models \n",
    " would \"align to the values of humanity.\" The move was from its public program launched in May 2023. \n",
    " The company wanted the program to be considered separate from its commercial endeavors. \n",
    " The move came amid intense scrutiny from regulators around the world\n",
    "\"\"\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer the question based on the context below. If the question cannot be answered using the\n",
      "information, provide answer with \"I Don't know\".\n",
      "### \n",
      "\n",
      "Context: \n",
      "    Large Language Models (LLMs) are the latest models used in NLP. Their superior performance \n",
      "over smaller models has made them incredibly useful for developers building NLP enabled applications.\n",
      "These models can be accessed via Hugging Face's \"transformers\" library, via OpenAI using the \"openai\"\n",
      "library, and via Cohere using the \"cohere\" library.\n",
      "\n",
      "##\n",
      "\n",
      "To use OpenAI's GPT-3 model for completion (generation) tasks, you first need to get an API\n",
      " key from 'https://openai.com/account/api-keys'\n",
      "\n",
      "##\n",
      "\n",
      " Ernest Shackleton (15 February 1874 – 5 January 1922) led three British expeditions to the \n",
      "  Antarctic during the Heroic Age of Antarctic Exploration. He and three companions established \n",
      "  a new record Farthest South latitude, 112 miles (180 km) from the South Pole, as part of the Nimrod\n",
      "   Expedition of 1907–1909, and Shackleton was knighted on his return home. He planned the Imperial \n",
      "  Trans-Antarctic Expedition of 1914–1917 but his ship, Endurance, became trapped in pack ice and \n",
      "  then sank on 21 November 1915.\n",
      "\n",
      "\n",
      "##\n",
      "\n",
      "In January 2024, OpenAI announced the formation of a new Collective \n",
      " Alignment team that would aim to implement ideas from the public about how to ensure its models \n",
      " would \"align to the values of humanity.\" The move was from its public program launched in May 2023. \n",
      " The company wanted the program to be considered separate from its commercial endeavors. \n",
      " The move came amid intense scrutiny from regulators around the world\n",
      "\n",
      "\n",
      "###\n",
      "Question: Tell me something about OpenAI and it's llms\n",
      "\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "context_string = '\\n\\n##\\n\\n'.join(context)\n",
    "prompt = f\"\"\"\n",
    "\n",
    "Answer the question based on the context below. If the question cannot be answered using the\n",
    "information, provide answer with \"I Don't know\".\n",
    "### \n",
    "\n",
    "Context: {context_string}\n",
    "\n",
    "###\n",
    "Question: Tell me something about OpenAI and it's llms\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" To use OpenAI's GPT-3 model for completion (generation) tasks, you first need to get an API key from 'https://openai.com/account/api-keys'\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = client.completions.create(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    prompt = prompt,\n",
    "    max_tokens = 256\n",
    ")\n",
    "\n",
    "res.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoder_name = \"r50k_base\"\n",
    "tokenizer = tiktoken.get_encoding(encoder_name)\n",
    "len(tokenizer.encode(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can access OpenAI's GPT-3 model for completion tasks by getting an API key from their website.\n"
     ]
    }
   ],
   "source": [
    "res = client.completions.create(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    prompt = prompt,\n",
    "    max_tokens = 3685\n",
    ")\n",
    "\n",
    "print(res.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
