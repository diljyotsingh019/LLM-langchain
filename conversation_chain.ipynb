{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory,\n",
    "                                                  ConversationSummaryMemory,\n",
    "                                                  ConversationBufferWindowMemory,\n",
    "                                                  ConversationKGMemory,\n",
    "                                                  ConversationSummaryBufferMemory)\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from getpass import getpass\n",
    "import inspect\n",
    "import tiktoken\n",
    "import os\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model_name = \"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.run(query)\n",
    "        print(f\"Spent a total of {cb.total_tokens} tokens\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm = llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_buf = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Good Morning AI?',\n",
       " 'history': '',\n",
       " 'response': \" Good morning! It's currently 9:00 AM here in my server room. The temperature is a comfortable 72 degrees Fahrenheit and the humidity is at 45%. How can I assist you today?\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buf(\"Good Morning AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 196 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Ah, that's a fascinating topic! I have access to a vast amount of external knowledge through my database and can easily integrate it with my language models. In fact, I have been trained on a variety of external knowledge sources such as Wikipedia, news articles, and scientific papers. Is there a specific area or topic you would like me to focus on?\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation_buf,\n",
    "             \"My interest here is to explore the potential of integrating the Large Language Models with the external knowledge\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 256 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes, I am connected to multiple external databases that are constantly updated with new information. These databases include knowledge from various fields such as science, history, literature, and more. Is there a specific database you would like me to access?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation_buf,\n",
    "             \"Are you connected to an external database?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 316 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure, I can access the medical database for you. It contains a vast amount of information on diseases, treatments, medications, and more. Is there a specific topic or question you would like me to search for in the medical database?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation_buf,\n",
    "             \"Access the database with the medical domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_sum = ConversationChain(llm =llm, \n",
    "                                     memory= ConversationSummaryMemory(llm = llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(conversation_sum.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 448 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's a fascinating topic! Large Language Models, also known as LLMs, are a type of artificial intelligence that use deep learning techniques to process and generate human language. They have been trained on vast amounts of text data and have shown impressive abilities in natural language processing tasks. By integrating them with external knowledge, we can potentially enhance their capabilities and make them even more useful in various applications.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation_sum,\n",
    "             \"My interest here is to explore the potential of integrating the Large Language Models with the external knowledge\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer memory conversation length: 491\n",
      "\n",
      " Summary memory conversation length: 64\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "print(f\"Buffer memory conversation length: {len(tokenizer.encode(conversation_buf.memory.buffer))}\\n\\n\",\n",
    "      f\"Summary memory conversation length: {len(tokenizer.encode(conversation_sum.memory.buffer))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only remembers last k conversation instead of the entire conversation history like buffer memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_bufw = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory= ConversationBufferWindowMemory(k=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 651 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's a great topic to explore! Large Language Models, or LLMs, are a type of artificial intelligence that have been trained on massive amounts of text data. They are able to perform impressive natural language processing tasks, such as language translation, text summarization, and question-answering. By integrating them with external knowledge, such as databases or ontologies, their capabilities can potentially be enhanced for various applications. This could include improving accuracy and efficiency in tasks like information retrieval, knowledge extraction, and text generation.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation_sum,\n",
    "             \"My interest here is to explore the potential of integrating the Large Language Models with the external knowledge\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_sum_buf = ConversationChain(llm = llm, memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm, max_token_limit = 650\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 874 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's a great topic to explore! Large Language Models, or LLMs, are a type of artificial intelligence that have been trained on massive amounts of text data. They are able to perform impressive natural language processing tasks, such as language translation, text summarization, and question-answering. By integrating them with external knowledge, such as databases or ontologies, we can potentially enhance their capabilities for various applications. For example, integrating LLMs with a medical database could improve their accuracy in diagnosing diseases or generating medical reports. It could also make them more efficient in tasks like information retrieval, where they can quickly access relevant information from a large knowledge base. Overall, integrating LLMs with external knowledge has the potential to greatly improve their performance and expand their applications. Is there a specific area or application you are interested in exploring?\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation_sum,\n",
    "             \"My interest here is to explore the potential of integrating the Large Language Models with the external knowledge\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_kg = ConversationChain(llm = llm, memory = ConversationKGMemory(\n",
    "    llm=llm\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 1233 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's a fascinating topic! Large Language Models, also known as LLMs, are a type of artificial intelligence that use deep learning techniques to process and generate human language. They have been trained on vast amounts of text data and have shown impressive abilities in natural language processing tasks. By integrating them with external knowledge, we can potentially enhance their capabilities and make them even more useful in various applications. Is there a specific area or use case you are interested in exploring?\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation_kg,\n",
    "             \"My interest here is to explore the potential of integrating the Large Language Models with the external knowledge\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Large Language Models', 'external knowledge', 'can be integrated with'),\n",
       " ('Large Language Models', 'capabilities', 'can potentially enhance'),\n",
       " ('Large Language Models', 'various applications', 'can be useful in')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_kg.memory.kg.get_triples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
